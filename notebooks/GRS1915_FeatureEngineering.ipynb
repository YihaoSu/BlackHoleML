{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "For reference, I'm going to go into a bit more detail on the feature engineering. \n",
    "We will engineer features based on the human classification to find those features that predict the\n",
    "observed properties of the light curves best.\n",
    "\n",
    "There are two parts to feature engineering:\n",
    "1. using cross validation to gauge what effect certain hyperparameters have on the final classification\n",
    "2. comparing various features against each other and how effective they actually are in classification.\n",
    "\n",
    "We'll do 1 first, then 2. \n",
    "\n",
    "## Setting Hyperparameters\n",
    "\n",
    "If we restrict ourselves to summary statistics (rather than using 2D histograms of hardness ratios and/or \n",
    "full/binned periodograms), there are only a few hyperparameters left:\n",
    "\n",
    "- the duration of a segment\n",
    "- the overlap between consecutive segments\n",
    "- the number of time bins used in the autoregressive model\n",
    "- the time binning (if any) in the autoregressive model\n",
    "- the regularization parameter in the autoregressive model\n",
    "- the number of PCA bins in the power spectrum representation\n",
    "\n",
    "We will incorporate all of this into a pipeline and cross-validate across a bunch \n",
    "of parameters to find out how well we can predict the (human-classified) data from\n",
    "linear filter weights + a random forest alone.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/daniela/sw/miniconda/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "/scratch/daniela/sw/miniconda/lib/python2.7/site-packages/IPython/kernel/__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated. You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=2.5, rc={\"axes.labelsize\": 26})\n",
    "plt.rc(\"font\", size=24, family=\"serif\", serif=\"Computer Sans\")\n",
    "plt.rc(\"axes\", titlesize=20, labelsize=20) \n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import powerspectrum\n",
    "import generaltools as gt\n",
    "import feature_extraction\n",
    "#import grs1915_utils\n",
    "\n",
    "import glob\n",
    "import scipy.stats\n",
    "\n",
    "#import sys\n",
    "\n",
    "#sys.path.append(\"/Users/danielahuppenkothen/work/repositories/LightEcho/code/\")\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.cm as cmap\n",
    "\n",
    "import linearfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the data and split it into training, test and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../../grs1915_125ms_clean.dat\", \"r\") as f:\n",
    "    d_all = pickle.load(f)\n",
    "\n",
    "    \n",
    "## total number of light curves\n",
    "n_lcs = len(d_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to want to use some rebinning in conjunction with the autoregressive model to control for noise.\n",
    "\n",
    "We need to define the rebinning of the light curve in a way that scikit-learn \n",
    "can parse, i.e. as a transformer class. This is kind of stupidly simple, but it'll come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RebinTimeseries(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, n=4, method=\"average\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize hyperparameters\n",
    "\n",
    "        :param n: number of samples to bin\n",
    "        :param method: \"average\" or \"sum\" the samples within a bin?\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n ## save number of bins to average together\n",
    "        self.method = method\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self,X):\n",
    "        \"\"\"\n",
    "        I don't really need a fit method!\n",
    "        \"\"\"\n",
    "        \n",
    "        ## set number of light curves (L) and \n",
    "        ## number of samples per light curve (k)\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def transform(self, X):\n",
    "        self.L, self.K = X.shape\n",
    "\n",
    "    \n",
    "        ## set the number of binned samples per light curve\n",
    "        K_binned = int(self.K/self.n)\n",
    "        \n",
    "        ## if the number of samples in the original light curve\n",
    "        ## is not divisible by n, then chop off the last few samples of \n",
    "        ## the light curve to make it divisible\n",
    "        #print(\"X shape: \" + str(X.shape))\n",
    "\n",
    "        if K_binned*self.n < self.K:\n",
    "            X = X[:,:self.n*K_binned]\n",
    "        \n",
    "        ## the array for the new, binned light curves\n",
    "        X_binned = np.zeros((self.L, K_binned))\n",
    "        \n",
    "        if self.method in [\"average\", \"mean\"]:\n",
    "            method = np.mean\n",
    "        elif self.method == \"sum\":\n",
    "            method = np.sum\n",
    "        else:\n",
    "            raise Exception(\"Method not recognized!\")\n",
    "        \n",
    "        #print(\"X shape: \" + str(X.shape))\n",
    "        #print(\"L: \" + str(self.L))\n",
    "        for i in xrange(self.L):\n",
    "            t_reshape = X[i,:].reshape((K_binned, self.n))\n",
    "            X_binned[i,:] = method(t_reshape, axis=1)\n",
    "        \n",
    "        return X_binned\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def score(self, X):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "\n",
    "        self.fit(X)\n",
    "        X_binned = self.transform(X)\n",
    "\n",
    "        return X_binned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll need to write a class that takes the data and makes features, in the same scikit-learn syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import feature_extraction\n",
    "import sys \n",
    "\n",
    "## boundaries for power bands\n",
    "pcb = {\"pa_min\":0.0039, \"pa_max\":0.031,\n",
    "       \"pb_min\":0.031, \"pb_max\":0.25,\n",
    "       \"pc_min\":0.25, \"pc_max\":2.0,\n",
    "       \"pd_min\":2.0, \"pd_max\":16.0}\n",
    "\n",
    "\n",
    "class MakeFeatures(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, n=1, k=10, lamb=0.1, n_components=3):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize hyperparameters\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n : int\n",
    "            The number of time steps in the light curve to rebin\n",
    "            \n",
    "        k : int\n",
    "            number of samples to use in autoregressive model\n",
    "            \n",
    "        lamb : float\n",
    "            the regularization parameter for the autoregressive model\n",
    "            \n",
    "        n_components : int\n",
    "            number of components in the PCA decomposition\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.n = n\n",
    "        self.k = k \n",
    "        self.lamb = lamb\n",
    "        self.n_components = n_components\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def fit(self,X):\n",
    "        \"\"\"\n",
    "        I don't really need a fit method!\n",
    "        \"\"\"\n",
    "        \n",
    "        ## set number of light curves (L) and \n",
    "        ## number of samples per light curve (k)\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        transform time series into features.\n",
    "        \n",
    "        X should be a a matrix of dimension (N, L, J), where N is \n",
    "        the number of samples, L is the set of energy bins and J is \n",
    "        the number of time steps per light curve.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        features = [] # empty list for features        \n",
    "        \n",
    "        # total counts in the light curve are stored in the second column for each \n",
    "        # sample\n",
    "        #print(\"Extracting counts ...\")\n",
    "        counts = np.array([s[:,1] for s in X])\n",
    "\n",
    "        #print(\"rebinning time series ...\")\n",
    "        rt = RebinTimeseries(n=self.n, method=\"average\")\n",
    "        counts_binned = rt.fit_transform(counts)\n",
    "                \n",
    "        #print(\"extracting weights from AR model ...\")\n",
    "        # weights of the autoregressive model\n",
    "        ww = feature_extraction.linear_filter(counts_binned, k=self.k, lamb=self.lamb)\n",
    "\n",
    "        #print(\"extracting PCA components from PSDs ...\")\n",
    "        # PCA on the power spectrum\n",
    "        pca = feature_extraction.psd_pca(X, n_components=self.n_components)\n",
    "        \n",
    "        #print(\"extracting summary features ...\")\n",
    "        for s in X:\n",
    "\n",
    "            features_temp = []\n",
    "\n",
    "            ## time series summary features\n",
    "            fmean, fmedian, fvar, fskew, fkurt = feature_extraction.timeseries_features(s)\n",
    "            features_temp.extend([fmean, fmedian, np.log(fvar), fskew, fkurt])\n",
    "\n",
    "            ## PSD summary features\n",
    "            maxfreq, psd_a, psd_b, psd_c, psd_d, pc1, pc2 = feature_extraction.psd_features(s, pcb)\n",
    "            \n",
    "            if len(maxfreq) == 0:\n",
    "                features_temp.extend([np.log(psd_a), np.log(psd_b), np.log(psd_c), np.log(psd_d), \n",
    "                                      np.log(pc1), np.log(pc2)])\n",
    "            else:\n",
    "                features_temp.extend([np.log(maxfreq), np.log(psd_a), np.log(psd_b), \n",
    "                                      np.log(psd_c), np.log(psd_d), np.log(pc1), np.log(pc2)])\n",
    "\n",
    "            mu1, mu2, cov, skew, kurt = feature_extraction.hr_fitting(s)\n",
    "            features_temp.extend([mu1, mu2])\n",
    "            features_temp.extend([np.log(cov[0]), cov[1], np.log(cov[3])])\n",
    "            features_temp.extend(list(skew))\n",
    "            features_temp.extend(list(kurt))\n",
    "\n",
    "            features.append(features_temp)\n",
    "\n",
    "        features_all = np.hstack((np.array(features), np.array(ww)))\n",
    "        features_all = np.hstack((np.array(features_all), np.array(pca)))\n",
    "        \n",
    "        return features_all\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def score(self, X):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \n",
    "        self.fit(X)\n",
    "        features = self.transform(X)\n",
    "        return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we need to extract segments and give each a group label:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data set into train, test and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 light curves in the validation set.\n",
      "There are 566 light curves in the test set.\n",
      "The number of states in the training set is 17\n",
      "The number of states in the test set is 17\n",
      "The number of states in the validation set is 17\n",
      "These is the distribution of states in the training set: \n",
      "chi1      56\n",
      "chi2      36\n",
      "rho       31\n",
      "kappa     28\n",
      "chi4      28\n",
      "delta     28\n",
      "theta     26\n",
      "beta      25\n",
      "gamma     19\n",
      "phi       14\n",
      "chi3       8\n",
      "nu         8\n",
      "mu         8\n",
      "lambda     6\n",
      "alpha      5\n",
      "eta        5\n",
      "omega      3\n",
      "dtype: int64\n",
      "================================================================\n",
      "These is the distribution of states in the validation set: \n",
      "chi1      26\n",
      "chi2      15\n",
      "rho       13\n",
      "theta     12\n",
      "gamma     11\n",
      "chi4      10\n",
      "nu         7\n",
      "delta      7\n",
      "beta       7\n",
      "mu         6\n",
      "kappa      5\n",
      "alpha      4\n",
      "phi        4\n",
      "eta        2\n",
      "omega      1\n",
      "chi3       1\n",
      "lambda     1\n",
      "dtype: int64\n",
      "================================================================\n",
      "These is the distribution of states in the test set: \n",
      "chi1      18\n",
      "chi2      17\n",
      "theta     10\n",
      "chi4       9\n",
      "rho        9\n",
      "beta       7\n",
      "phi        6\n",
      "gamma      6\n",
      "kappa      5\n",
      "delta      4\n",
      "chi3       3\n",
      "mu         3\n",
      "lambda     2\n",
      "omega      2\n",
      "nu         2\n",
      "eta        1\n",
      "alpha      1\n",
      "dtype: int64\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "d_all_train, d_all_val, d_all_test = feature_extraction.split_dataset(d_all, \n",
    "                                                                      train_frac = 0.6, \n",
    "                                                                      validation_frac = 0.2, \n",
    "                                                                      test_frac = 0.2, seed=20160615)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract segments of equal length for all three sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_extraction.py:128: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  dtemp = data[istart:iend]\n"
     ]
    }
   ],
   "source": [
    "seg_length = 1024.\n",
    "overlap = 256.\n",
    "dt = 0.125\n",
    "\n",
    "segments_train, labels_train, nsegments_train = feature_extraction.extract_segments(d_all_train, \n",
    "                                                                                    seg_length=seg_length, \n",
    "                                                                                    overlap=overlap, \n",
    "                                                                                    dt=dt)\n",
    "\n",
    "segments_test, labels_test, nsegments_test = feature_extraction.extract_segments(d_all_test, \n",
    "                                                                                 seg_length=seg_length, \n",
    "                                                                                 overlap=overlap, \n",
    "                                                                                 dt=dt)\n",
    "\n",
    "segments_val, labels_val, nsegments_val = feature_extraction.extract_segments(d_all_val, \n",
    "                                                                              seg_length=seg_length, \n",
    "                                                                              overlap=overlap, \n",
    "                                                                              dt=dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_mask_train = labels_train != \"None\"\n",
    "label_mask_val= labels_val != \"None\"\n",
    "label_mask_test = labels_test != \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments_train_labelled = np.array(segments_train)[label_mask_train]\n",
    "labels_train_labelled = labels_train[label_mask_train]\n",
    "nsegments_train_labelled = nsegments_train[label_mask_train]\n",
    "\n",
    "segments_test_labelled = np.array(segments_test)[label_mask_test]\n",
    "labels_test_labelled = labels_test[label_mask_test]\n",
    "nsegments_test_labelled = nsegments_test[label_mask_test]\n",
    "\n",
    "segments_val_labelled = np.array(segments_val)[label_mask_val]\n",
    "labels_val_labelled = labels_val[label_mask_val]\n",
    "nsegments_val_labelled = nsegments_val[label_mask_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the individual components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mf = MakeFeatures(n=1, k=7, lamb=100, n_components=3)\n",
    "features = mf.fit_transform(np.vstack([segments_train_labelled, segments_val_labelled]), \n",
    "                            np.hstack([labels_train_labelled, labels_val_labelled]))\n",
    "#f_val = mf.fit_transform(segments_val_labelled, labels_val_labelled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "## set the estimators to glue together:\n",
    "lr = LogisticRegression(penalty=\"l2\", class_weight=None, C=10.0,\n",
    "                        solver=\"lbfgs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(features[:len(segments_train_labelled)], labels_train_labelled[:len(segments_train_labelled)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84210526315789469"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(features[len(segments_train_labelled):,:], labels_val_labelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start building estimators for the cross-validation task. However, we need to make *all* features together, because we have to do the feature extraction on the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import LabelKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a piece of example code running the cross-validation. We've only picked one set of parameters here, because everything else would take too long for a notebook. The corresponding code to run is in `parameter_estimation.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-d01240961391>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-d01240961391>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    cc = [0.001, 0.01, 0.1, 1., 10. 40., 100., 1000.0]\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## parameters to search using GridSearchCV\n",
    "nn = [1.]#[1,4,8,80] ## number of samples to rebin\n",
    "kk = [7]#[2,5,7,10,20] ## number of weights in the linear filter\n",
    "lamb = [100]#[1.0, 10.,100., 1000. ] ## regularization parameter for ridge regression\n",
    "n_components = [3]#[1, 2, 3, 5, 10, 20]\n",
    "cc = [0.001, 0.01, 0.1, 1., 10. 40., 100., 1000.0]\n",
    "\n",
    "# folds to use in cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# empty lists for validation scores\n",
    "all_scores = []\n",
    "\n",
    "# stack all segments together\n",
    "seg_all_labelled = np.concatenate([segments_train_labelled, segments_val_labelled, segments_test_labelled])\n",
    "# stack all segment indices together\n",
    "nseg_all_labelled = np.hstack([nsegments_train_labelled, nsegments_val_labelled, nsegments_test_labelled])\n",
    "\n",
    "# store number of samples in each set, for use below\n",
    "ntrain = len(segments_train_labelled)\n",
    "nval = len(segments_val_labelled)\n",
    "ntest = len(segments_test_labelled)\n",
    "\n",
    "# loop over all parameters\n",
    "for i, n in enumerate(nn):\n",
    "    for j, k in enumerate(kk):\n",
    "        for l, lm in enumerate(lamb):\n",
    "            for m, nc in enumerate(n_components):\n",
    "                # make features using whole feature set\n",
    "                # don't need to repeat this for each iteration of finding \n",
    "                # the regularization parameter for the logistic regression estimator\n",
    "                mf = MakeFeatures(n=n, k=k, lamb=lm, n_components=nc)\n",
    "                features = mf.fit_transform(seg_all_labelled)\n",
    "\n",
    "                pars = {\"n\":n, \"k\":k, \"lamb\":lm, \"n_components\":nc}\n",
    "\n",
    "                # make the GroupKFold cross validation generator\n",
    "                group_kfold = LabelKFold(nsegments_train_labelled, n_folds=n_folds)\n",
    "\n",
    "                # make a LogisticRegression object\n",
    "                lr = LogisticRegression(penalty=\"l2\", class_weight=None, \n",
    "                                        solver=\"lbfgs\")\n",
    "\n",
    "                # instantiate the GridSearchCV object for searching over regularization parameters\n",
    "                grid_lr = GridSearchCV(lr, dict(C=cc), cv=group_kfold, verbose=3, n_jobs=1,\n",
    "                                         scoring=\"f1_macro\")\n",
    "                # do grid search\n",
    "                grid_lr.fit(features[:ntrain], labels_train_labelled)\n",
    "\n",
    "                val_score = grid_lr.score(features[ntrain:ntrain+nval], labels_val_labelled)\n",
    "\n",
    "                score_dict = {\"train_scores\": grid_lr.grid_scores_, \"val_score\":val_score, \"pars\":pars}\n",
    "\n",
    "                all_scores.append(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get out the validation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_scores = np.array([s[\"val_score\"] for s in all_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's an array of the mean cross validation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_scores = [[m.mean_validation_score for m in s[\"train_scores\"]] for s in all_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've done this using `parameter_estimation.py`, so we can now load the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../../grs1915_best_estimator.dat\", \"r\") as f:\n",
    "    all_scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_scores = np.array(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ {'train_scores': [mean: 0.27209, std: 0.07768, params: {'C': 0.001}, mean: 0.29219, std: 0.09090, params: {'C': 0.01}, mean: 0.31579, std: 0.08484, params: {'C': 0.1}, mean: 0.28240, std: 0.06077, params: {'C': 1.0}, mean: 0.26143, std: 0.08122, params: {'C': 10.0}, mean: 0.27879, std: 0.12159, params: {'C': 100.0}, mean: 0.27929, std: 0.11816, params: {'C': 1000.0}], 'pars': {'lamb': 1.0, 'k': 2, 'n_components': 1, 'n': 1}, 'val_score': 0.25138245421177091},\n",
       "       {'train_scores': [mean: 0.31068, std: 0.12918, params: {'C': 0.001}, mean: 0.29475, std: 0.05967, params: {'C': 0.01}, mean: 0.32149, std: 0.07394, params: {'C': 0.1}, mean: 0.27877, std: 0.08493, params: {'C': 1.0}, mean: 0.26896, std: 0.07110, params: {'C': 10.0}, mean: 0.26492, std: 0.07467, params: {'C': 100.0}, mean: 0.26366, std: 0.06606, params: {'C': 1000.0}], 'pars': {'lamb': 1.0, 'k': 2, 'n_components': 2, 'n': 1}, 'val_score': 0.38123480767778245}], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_scores = np.array([s[\"val_score\"] for s in all_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_max_ind = np.where(val_scores == np.max(val_scores))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_set = all_scores[val_max_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ {'train_scores': [mean: 0.29892, std: 0.07070, params: {'C': 0.001}, mean: 0.40702, std: 0.14274, params: {'C': 0.01}, mean: 0.40240, std: 0.07367, params: {'C': 0.1}, mean: 0.33244, std: 0.12174, params: {'C': 1.0}, mean: 0.35095, std: 0.09974, params: {'C': 10.0}, mean: 0.36771, std: 0.08344, params: {'C': 100.0}, mean: 0.33793, std: 0.10751, params: {'C': 1000.0}], 'pars': {'lamb': 1000.0, 'k': 10, 'n_components': 10, 'n': 1}, 'val_score': 0.48089980748228928}], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_scores = np.array([[m.mean_validation_score for m in s[\"train_scores\"]] for s in all_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43039571497742818"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_ind = np.where(mean_scores == np.max(mean_scores))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35929676,  0.30263375,  0.37591296,  0.43039571,  0.39724662,\n",
       "         0.38577056,  0.39399234]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores[max_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_max_scores = all_scores[max_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ {'train_scores': [mean: 0.35930, std: 0.07795, params: {'C': 0.001}, mean: 0.30263, std: 0.06860, params: {'C': 0.01}, mean: 0.37591, std: 0.10152, params: {'C': 0.1}, mean: 0.43040, std: 0.10592, params: {'C': 1.0}, mean: 0.39725, std: 0.09884, params: {'C': 10.0}, mean: 0.38577, std: 0.09161, params: {'C': 100.0}, mean: 0.39399, std: 0.05600, params: {'C': 1000.0}], 'pars': {'lamb': 10000.0, 'k': 50, 'n_components': 50, 'n': 1}, 'val_score': 0.33584502740205424}], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_max_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgoAAAFpCAYAAAD9SQA8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRFAAAABG/x9ncT7yZYGZ3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcaf1f918d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mean_scores.flatten(), bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We find the best validation score for a model with \n",
    "    - $k = 10$ for the linear model\n",
    "    - $\\lambda = 1000$ for the regularization of the linear model\n",
    "    - $n = 1$, i.e. no binning of the light curves\n",
    "    - $n_{\\mathrm{components}} = 10$, i.e. only one of the PCA components\n",
    "    - $C = 1.0$\n",
    "    \n",
    "We can now use this information to extract features. \n",
    "We will extract summary statistics for segments of 1024s and 256s duration as \n",
    "well as the weights of a linear model as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir=\"../../\"\n",
    "seg_length_supervised =1024.0\n",
    "seg_length_unsupervised =1024.0\n",
    "overlap_all = 256.\n",
    "\n",
    "k = 10\n",
    "lamb = 1000 \n",
    "n = 1\n",
    "n_components= 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../../grs1915_125ms_clean.dat\", \"r\") as f:\n",
    "    d_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of states in the training set is 17\n",
      "The number of states in the test set is 17\n",
      "The number of states in the validation set is 17\n",
      "Checking for NaN in the training set ...\n",
      "4669 samples in training data set before checking for NaNs.\n",
      "2450 samples in test data set before checking for NaNs.\n",
      "Checking for NaN in the test set ...\n",
      "4669 samples in training data set after checking for NaNs.\n",
      "2450 samples in test data set before after for NaNs.\n",
      "Checking for NaN in the validation set ...\n",
      "2094 samples in validation data set after checking for NaNs.\n"
     ]
    }
   ],
   "source": [
    "reload(feature_extraction)\n",
    "feature_extraction.extract_all(d_all, seg_length_all=[1024.], overlap=[256.],\n",
    "                               val=True, train_frac=0.5, validation_frac = 0.25, test_frac = 0.25,\n",
    "                               k=k, lamb=lamb, n_components=n_components,\n",
    "                               datadir=\"../../\", seed=20160615)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found outlier in validation set\n",
      "after removal: []\n"
     ]
    }
   ],
   "source": [
    "features, labels, lc, hr, tstart = feature_engineering.load_features(datadir, 1024.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2349, 51)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"test\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our feature vector to actually determine what the *most descriptive* features are. \n",
    "\n",
    "## Finding the most descriptive features\n",
    "I'm going to start with all of the summary features and use a greedy approach: out of all summary features, which is the one that alone predicts the human classification best? I am going to keep that, and then add a second feaure, again going through the entire list of left-over features to figure out the best combination of two, and so on, until I reach the end of the 13 features. \n",
    "\n",
    "In the second step, I can add feature sets like the entire heatmap of the hardness diagram, or the periodogram to the game, but we'll keep it simple(ish) with the summary features only for now.\n",
    "\n",
    "For this task, I'm going to use Random Forests, because I have to pick an algorithm and this one seems to be pretty robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datadir= \"../../\"\n",
    "seg_length_supervised = 1024.\n",
    "\n",
    "features_train_full = np.loadtxt(datadir+\"grs1915_%is_features_train.txt\"%seg_length_supervised)\n",
    "features_test_full = np.loadtxt(datadir+\"grs1915_%is_features_test.txt\"%seg_length_supervised)\n",
    "features_val_full = np.loadtxt(datadir+\"grs1915_%is_features_val.txt\"%seg_length_supervised)\n",
    "\n",
    "labels_test_full = np.array(gt.conversion(datadir+\"grs1915_%is_labels_test.txt\"%seg_length_supervised)[0])\n",
    "labels_train_full = np.array(gt.conversion(datadir+\"grs1915_%is_labels_train.txt\"%seg_length_supervised)[0])\n",
    "labels_val_full = np.array(gt.conversion(datadir+\"grs1915_%is_labels_val.txt\"%seg_length_supervised)[0])\n",
    "\n",
    "tstart_train_full = np.loadtxt(datadir+\"grs1915_%is_tstart_train.txt\"%seg_length_supervised)\n",
    "tstart_test_full = np.loadtxt(datadir+\"grs1915_%is_tstart_test.txt\"%seg_length_supervised)\n",
    "tstart_val_full = np.loadtxt(datadir+\"grs1915_%is_tstart_val.txt\"%seg_length_supervised)\n",
    "\n",
    "features_all_full = np.concatenate((features_train_full, features_val_full, features_test_full))\n",
    "\n",
    "features_train = features_train_full[np.where(labels_train_full != \"None\")]\n",
    "features_test = features_test_full[np.where(labels_test_full != \"None\")]\n",
    "features_val= features_val_full[np.where(labels_val_full != \"None\")]\n",
    "\n",
    "labels_train= labels_train_full[np.where(labels_train_full != \"None\")]\n",
    "labels_test = labels_test_full[np.where(labels_test_full != \"None\")]\n",
    "labels_val = labels_val_full[np.where(labels_val_full != \"None\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"There are %i training samples with %i features\"%features_train.shape)\n",
    "print(\"There are %i validation samples with %i features\"%features_val.shape)\n",
    "print(\"There are %i test samples with %i features\"%features_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features here are:\n",
    "* mean count rate\n",
    "* median count rate\n",
    "* total variance in the count rate\n",
    "* skew of the countrate\n",
    "* kurtosis of the count rate\n",
    "* Frequency where the PSD has its maximum\n",
    "* Power Spectral Band A\n",
    "* Power Spectral Band B\n",
    "* Power Spectral Band C\n",
    "* Power Spectral Band D\n",
    "* Power Spectral Color 1 (PSDc/PSDa)\n",
    "* Power Spectral Color 2 (PSDb/PSDd)\n",
    "* mean of hardness ratio HR1\n",
    "* mean of hardness ratio HR2\n",
    "* flattened covariance matrix of HR1 and HR2\n",
    "* skew of HR1 and HR2\n",
    "* kurtosis of HR1 and HR2\n",
    "* 10 weights from the linear filter\n",
    "* 10 PCA components decomposing the power spectrum\n",
    "\n",
    "for a total of 31 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "score = []\n",
    "best_params = []\n",
    "## first feature\n",
    "for i in range(features_train.shape[1]):\n",
    "    ft = np.atleast_2d(features_train[:,i]).T\n",
    "    fv = np.atleast_2d(features_val[:,i]).T\n",
    "\n",
    "    ### scale features\n",
    "    scaler_train = StandardScaler().fit(ft)\n",
    "    fscaled_train = scaler_train.transform(ft)\n",
    "    #print(fscaled_train.shape)\n",
    "    \n",
    "    scaler_val = StandardScaler().fit(fv)\n",
    "    fscaled_val = scaler_val.transform(fv)\n",
    "    \n",
    "    ### Random Forest Classifier\n",
    "    params = {'max_depth': [5,6,7,10,12,15,20,50,100,200]}#,\n",
    "    grid_rfc = GridSearchCV(RandomForestClassifier(n_estimators=300), param_grid=params,\n",
    "                            verbose=0, n_jobs=10)\n",
    "\n",
    "    grid_rfc.fit(fscaled_train, labels_train)\n",
    "    print(\"Best results for the Random Forest run:\")\n",
    "    print(\"Best parameter: \" + str(grid_rfc.best_params_))\n",
    "    best_params.append(grid_rfc.best_params_)\n",
    "    print(\"Training accuracy: \" + str(grid_rfc.score(fscaled_train, labels_train)))\n",
    "    print(\"Validation accuracy: \" + str(grid_rfc.score(fscaled_val, labels_val)))\n",
    "    score.append(grid_rfc.score(fscaled_val, labels_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_ind = np.where(score == np.max(score))[0]\n",
    "max_score = score[max_ind]\n",
    "print(\"The maximum validation score of %.3f was achieved for feature %i\"%(max_score, max_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like on the first try, the frequency where the PSD has its maximum does best in predicting the human classification on the validation set. Let's now automate this process for the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_all = []\n",
    "feature_ranking = []\n",
    "nfeatures = range(features_train.shape[1])\n",
    "features_new_train = []\n",
    "features_new_val = []\n",
    "features_new_test = []\n",
    "best_params_all = []\n",
    "\n",
    "for i in range(features_train.shape[1]):\n",
    "    print(\"I am on the %ith loop\"%i)\n",
    "    score = []\n",
    "    best_params = []\n",
    "    ## first feature\n",
    "    for j in nfeatures:\n",
    "        if j in feature_ranking:\n",
    "            continue\n",
    "        #print(\"I am on feature %i\"%j)\n",
    "        if len(features_new_train) == 0:\n",
    "            ft = np.atleast_2d(features_train[:,j]).T\n",
    "            fv = np.atleast_2d(features_val[:,j]).T\n",
    "            fte = np.atleast_2d(features_test[:,j]).T\n",
    "        else:\n",
    "            ft = np.concatenate((features_new_train, ft), 1)\n",
    "            fv = np.concatenate((features_new_val, fv), 1)\n",
    "            fte = np.concatenate((features_new_test, fte), 1)\n",
    "        ### scale features\n",
    "        f_all = np.concatenate((ft, fv, fte))\n",
    "        #print(\"NaN in row: \" + str(np.where(np.isnan(f_all))))\n",
    "        scaler_train = StandardScaler().fit(f_all)\n",
    "        fscaled_train = scaler_train.transform(ft)\n",
    "        \n",
    "        fscaled_val = scaler_train.transform(fv)\n",
    "        ### Random Forest Classifier\n",
    "        params = {'max_depth': [5,10,20,50,100,200,400]}#,\n",
    "        grid_rfc = GridSearchCV(RandomForestClassifier(n_estimators=250), param_grid=params,\n",
    "                                verbose=0, n_jobs=15)\n",
    "        grid_rfc.fit(fscaled_train, labels_train)\n",
    "        best_params.append(grid_rfc.best_params_)\n",
    "        score.append(grid_rfc.score(fscaled_val, labels_val))\n",
    "    \n",
    "    score_all.append(score)\n",
    "    best_params_all.append(best_params)\n",
    "    best_ind = np.where(score == np.max(score))[0]\n",
    "    print(\"best_ind: \" + str(best_ind))\n",
    "    if len(best_ind) > 1:\n",
    "        best_ind = best_ind[0]\n",
    "    print(\"The best score in round \" + str(i) + \" is \" + str(np.max(score)))\n",
    "    n_best = nfeatures.pop(best_ind)\n",
    "    print(\"The best-ranked feature in round \" + str(i) + \" is \" + str(n_best))\n",
    "    feature_ranking.append(n_best)\n",
    "    if len(features_new_train) == 0:\n",
    "        features_new_train = np.atleast_2d(features_train[:,n_best]).T\n",
    "        features_new_val = np.atleast_2d(features_val[:,n_best]).T\n",
    "        features_new_test = np.atleast_2d(features_test[:,n_best]).T\n",
    "    else:\n",
    "        features_new_train = np.concatenate((features_new_train, np.atleast_2d(features_train[:,n_best]).T), 1)\n",
    "        features_new_val = np.concatenate((features_new_val, np.atleast_2d(features_val[:,n_best]).T), 1)\n",
    "        features_new_test = np.concatenate((features_new_test, np.atleast_2d(features_test[:,n_best]).T), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_ranking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-afae4097a6b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Print the indices of the original feature vector by importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_ranking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_ranking' is not defined"
     ]
    }
   ],
   "source": [
    "## Print the indices of the original feature vector by importance\n",
    "print(feature_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In detail, the ranking of the feature gives: \n",
    "\n",
    "0. Power Spectral Colour 1\n",
    "1. variance of HR 1\n",
    "2. Power Spectral Band C\n",
    "3. median count rate\n",
    "4. one of the linear filter weights\n",
    "5. one of the linear filter weights\n",
    "6. Power Spectral Band D\n",
    "7. Power Spectral Band B\n",
    "8. kurtosis of the count rate\n",
    "9. one of the linear filter weights\n",
    "10. one of the linear filter weights\n",
    "11. Power spectral colour 2\n",
    "12. kurtosis of HR 2\n",
    "13. total variance in the light curve\n",
    "14. covariance between HR1 and HR2\n",
    "15. Frequency where the PSD has its maximum\n",
    "16. mean of HR1\n",
    "17. one of the linear filter weights\n",
    "18. skew of HR2\n",
    "19. mean count rate\n",
    "20. one of the linear filter weights\n",
    "21. one of the linear filter weights\n",
    "22. Power Spectral Band A\n",
    "23. kurtosis of HR1 \n",
    "24. skew of the count rate\n",
    "25. one of the linear filter weights\n",
    "26. skew of HR1\n",
    "27. mean of HR 2\n",
    "28. one of the linear filter weights\n",
    "29. one of the linear filter weights\n",
    "30. variance of HR 1\n",
    "\n",
    "There's a mix of all features (hardness ratios, power spectral, overall time series) here, which means that all components seem to be fairly important to the classification. The linear filter does pretty well, and most of the top ten features are related to the time series and the PSD. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the maximum of the validation scores for each run.\n",
    "score_max_all = np.array([np.max(s) for s in score_all])\n",
    "print(score_max_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the curve of the validation accuracy versus the number of features to get some picture of how much the different features add to the overall classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## plot the validation fraction versus the number of features in the classification\n",
    "plt.plot(np.arange(len(score_max_all))+1., score_max_all, \"o-\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Validation accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation fraction seems to saturate at about 80%.\n",
    "\n",
    "It's not clear whether this means\n",
    "- there's too little data\n",
    "- the human classification just sucks\n",
    "- the features don't accurately encapsulate the various behaviours in the data (e.g. QPOs)\n",
    "\n",
    "Let's print a confusion matrix for the run (1) with all features (2) with only 20 features and (3) with only 6 features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_params_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nfeatures = [6, 20, 31]\n",
    "\n",
    "for n in nfeatures:\n",
    "    features_new_red = np.concatenate((features_new_train[:,:n], features_new_val[:,:n], features_new_test[:,:n]))\n",
    "\n",
    "    scaler_train = StandardScaler().fit(features_new_red)\n",
    "    fscaled_train = scaler_train.transform(features_new_train[:,:n])\n",
    "    fscaled_val = scaler_train.transform(features_new_val[:,:n])\n",
    "    fscaled_test = scaler_train.transform(features_new_test[:,:n])\n",
    "\n",
    "    rfc_red = RandomForestClassifier(n_estimators=500, max_depth=400)\n",
    "    rfc_red.fit(fscaled_train, labels_train)\n",
    "    print(\"Training accuracy: \" + str(rfc_red.score(fscaled_train, labels_train)))\n",
    "    print(\"Validation accuracy: \" + str(rfc_red.score(fscaled_val, labels_val)))\n",
    "\n",
    "    labels_rfc_red = rfc_red.predict(fscaled_val)\n",
    "\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "    sns.set_style(\"white\") \n",
    "    unique_labels = np.unique(labels_test)\n",
    "    cm = confusion_matrix(labels_val, labels_rfc_red, labels=unique_labels)\n",
    "    cm = cm.astype(np.float64)\n",
    "    cm /= np.max(cm, axis=1)\n",
    "    print(type(cm))\n",
    "    print(cm)\n",
    "    \n",
    "    #print(unique_labels)\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.matshow(cm, cmap=cmap.Spectral_r )\n",
    "    ax1.set_title('Confusion matrix, %i features'%n)\n",
    "    #plt.colorbar()\n",
    "    ax1.set_ylabel('True label')\n",
    "    ax1.set_xlabel('Predicted label')\n",
    "    plt.xticks(range(len(unique_labels)), unique_labels, rotation=70)\n",
    "    plt.yticks(range(len(unique_labels)), unique_labels)\n",
    "    #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are no significant differences between the latter two, but there are between the run with 6 features and that with 20. For some classes, the 6 feature classifcation actually seems to do better, but this is likely due to overfitting when using many features.\n",
    "\n",
    "It seems like 20 is a good choice for the number of features. We can also print out the relative feature importances as derived from the Random Forest:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_new_full = np.concatenate((features_new_train, features_new_val, features_new_test))\n",
    "\n",
    "scaler_train = StandardScaler().fit(features_new_red)\n",
    "fscaled_train = scaler_train.transform(features_new_train)\n",
    "fscaled_val = scaler_train.transform(features_new_val)\n",
    "fscaled_test = scaler_train.transform(features_new_test)\n",
    "\n",
    "rfc_full = RandomForestClassifier(n_estimators=500, max_depth=400)\n",
    "rfc_full.fit(fscaled_train, labels_train)\n",
    "\n",
    "imp_rfc_full = rfc_full.feature_importances_\n",
    "\n",
    "std_full = np.std([tree.feature_importances_ for tree in rfc_full.estimators_],\n",
    "             axis=0)\n",
    "\n",
    "indices_full = np.argsort(imp_rfc_full)[::-1]\n",
    "\n",
    "# Print the feature ranking for the full feature vector\n",
    "print(\"Feature ranking, full feature vector:\")\n",
    "\n",
    "for f in range(31):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices_full[f], imp_rfc_full[indices_full[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(31), imp_rfc_full[indices_full],\n",
    "       color=\"r\", yerr=std_full[indices_full], align=\"center\")\n",
    "plt.xticks(range(31), indices_full)\n",
    "plt.xlim([-1, 32])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature importances derived from the trees isn't quite the same as from the greedy search. Note, however, that the inter-tree variability is fairly large, indicating that all of the features may contribute significantly to the classification.\n",
    "\n",
    "The top 5 features for the full feature set:\n",
    "1. mean count rate in the full light curve\n",
    "2. one of the linear filter weights\n",
    "3. mean of HR 2\n",
    "4. variance of HR 2\n",
    "5. Power Spectral Band A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Adding Many features help?\n",
    "\n",
    "tl;dr: **No**.\n",
    "\n",
    "There are two alternatives that would extend the features above. One is including either the full heat map of the hardness ratios, or the full periodogram. Perhaps we could use some clever dimensionality reduction on either of those to make the problem more clever. For now, I am simply going to test whether adding either the full periodogram or the HR heat maps will aid the classification task (hint: I don't think so!).\n",
    "\n",
    "We'll start with the heat maps of hardness ratios. These are basically HR1 and HR2 for each light curve combined in a 2D histogram with 20 by 20 bins with the same ranges in both dimensions for each light curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(datadir+\"grs1915_1024_clean_hrfull_features.dat\", \"r\")\n",
    "feature_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "features_train = np.array(feature_dict[\"train\"][0][\"features\"])\n",
    "features_val = np.array(feature_dict[\"val\"][0][0][\"features\"])\n",
    "features_test = np.array(feature_dict[\"test\"][0][\"features\"])\n",
    "print(\"features_train.shape: \" + str(features_train.shape))\n",
    "labels_train = feature_dict[\"train\"][1]\n",
    "labels_val = feature_dict[\"val\"][0][1]\n",
    "labels_test = feature_dict[\"test\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_all = np.concatenate((features_train, features_val, features_test))\n",
    "scaler_train = StandardScaler().fit(f_all)\n",
    "fscaled_train = scaler_train.transform(features_train)\n",
    "fscaled_val = scaler_train.transform(features_val)\n",
    "fscaled_test = scaler_train.transform(features_test)\n",
    "\n",
    "#print(fscaled_val.shape)\n",
    "### Random Forest Classifier\n",
    "params = {'max_depth': [3,5,7,10,15,20,30,50,75,100,150,200,250,300,400]}#,\n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(n_estimators=500), param_grid=params,\n",
    "                        verbose=0, n_jobs=4)\n",
    "grid_rfc.fit(fscaled_train, labels_train)\n",
    "print(\"Training accuracy: \" + str(grid_rfc.score(fscaled_train, labels_train)))\n",
    "print(\"Validation accuracy: \" + str(grid_rfc.score(fscaled_val, labels_val)))\n",
    "print(\"Test accuracy: \" + str(grid_rfc.score(fscaled_test, labels_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy of this model is actually *lower* than just using the summaries. Rubbish! This is clearly not the answer. What about using the full periodogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(datadir+\"grs1915_1024_clean_psfull_features.dat\", \"r\")\n",
    "feature_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "features_train = np.array(feature_dict[\"train\"][0][\"features\"])\n",
    "features_val = np.array(feature_dict[\"val\"][0][0][\"features\"])\n",
    "features_test = np.array(feature_dict[\"test\"][0][\"features\"])\n",
    "print(\"features_train.shape: \" + str(features_train.shape))\n",
    "labels_train = feature_dict[\"train\"][1]\n",
    "labels_val = feature_dict[\"val\"][0][1]\n",
    "labels_test = feature_dict[\"test\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_all = np.concatenate((features_train, features_val, features_test))\n",
    "scaler_train = StandardScaler().fit(f_all)\n",
    "fscaled_train = scaler_train.transform(features_train)\n",
    "fscaled_val = scaler_train.transform(features_val)\n",
    "fscaled_test = scaler_train.transform(features_test)\n",
    "\n",
    "#print(fscaled_val.shape)\n",
    "### Random Forest Classifier\n",
    "params = {'max_depth': [3,5,7,10,15,20,30,50,75,100,150,200,250,300,400]}#,\n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(n_estimators=500), param_grid=params,\n",
    "                        verbose=0, n_jobs=4)\n",
    "grid_rfc.fit(fscaled_train, labels_train)\n",
    "print(\"Training accuracy: \" + str(grid_rfc.score(fscaled_train, labels_train)))\n",
    "print(\"Validation accuracy: \" + str(grid_rfc.score(fscaled_val, labels_val)))\n",
    "print(\"Test accuracy: \" + str(grid_rfc.score(fscaled_test, labels_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result including the whole periodogram isn't much better (given some variance in the validation and test accuracy due to the probabilistic nature of the Random Forest classifier). Either we'll need to be a lot smarter about making our features, or this is as good as it's going to get.\n",
    "\n",
    "## How good is the computer compared to human classification?\n",
    "\n",
    "Let's check how good the computer does compared to the human classification. For this purpose, we'll be making plots that show light curve, PSD and HR diagram for (1) the segment in question, (2) six examples of the human-classified class, (3) six examples of the computer-classified class.\n",
    "These plots will be made for all misclsasified light curves, and serves as a sanity check of whether the computer is actually just misclassifying, or whether there are ambiguities in the human classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lc_all_full = gt.getpickle(datadir+\"grs1915_%is_lc_all.dat\"%seg_length_supervised)\n",
    "hr_all_full = gt.getpickle(datadir+\"grs1915_%is_hr_all.dat\"%seg_length_supervised)\n",
    "\n",
    "lc_train_full = lc_all_full[\"train\"]\n",
    "lc_test_full = lc_all_full[\"test\"]\n",
    "lc_val_full = lc_all_full[\"val\"]\n",
    "\n",
    "hr_train_full = hr_all_full[\"train\"]\n",
    "hr_test_full = hr_all_full[\"test\"]\n",
    "hr_val_full = hr_all_full[\"val\"]\n",
    "\n",
    "train_ind = np.where(labels_train_full != \"None\")[0]\n",
    "lc_train = np.array([lc_train_full[i] for i in train_ind])\n",
    "hr_train = np.array([hr_train_full[i] for i in train_ind])\n",
    "\n",
    "val_ind = np.where(labels_val_full != \"None\")[0]\n",
    "lc_val = np.array([lc_val_full[i] for i in val_ind])\n",
    "hr_val = np.array([hr_val_full[i] for i in val_ind])\n",
    "\n",
    "test_ind = np.where(labels_test_full != \"None\")[0]\n",
    "lc_test = np.array([lc_test_full[i] for i in test_ind])\n",
    "hr_test = np.array([hr_test_full[i] for i in test_ind])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to reshuffle the feature vector to match the reduced one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(feature_ranking)\n",
    "nfeatures = 20 ## the number of features to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the classification one more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_all = np.concatenate((features_new_train[:,:nfeatures], features_new_val[:,:nfeatures], features_new_test[:,:nfeatures]))\n",
    "\n",
    "scaler_train = StandardScaler().fit(f_all)\n",
    "fscaled_train = scaler_train.transform(features_train[:,:nfeatures])\n",
    "fscaled_val = scaler_train.transform(features_val[:,:nfeatures])\n",
    "fscaled_test = scaler_train.transform(features_test[:,:nfeatures])\n",
    "\n",
    "#print(fscaled_val.shape)\n",
    "### Random Forest Classifier\n",
    "params = {'max_depth': [3,5,7,10,15,20,30,50,75,100,150,200,250,300,400]}#,\n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(n_estimators=500), param_grid=params,\n",
    "                        verbose=0, n_jobs=4)\n",
    "grid_rfc.fit(fscaled_train, labels_train)\n",
    "print(\"Training accuracy: \" + str(grid_rfc.score(fscaled_train, labels_train)))\n",
    "print(\"Validation accuracy: \" + str(grid_rfc.score(fscaled_val, labels_val)))\n",
    "print(\"Test accuracy: \" + str(grid_rfc.score(fscaled_test, labels_test)))\n",
    "\n",
    "labels_rfc = grid_rfc.predict(fscaled_val)\n",
    "labels_rfc_test = grid_rfc.predict(fscaled_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot all light curves that are confused in the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import powerspectrum\n",
    "import copy\n",
    "import scipy.stats\n",
    "\n",
    "def plot_misclassifieds(features, trained_labels, real_labels, lc_all, hr_all, hr_limits,\n",
    "                        nexamples=6, namestr=\"misclassified\", datadir=\"./\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Find all mis-classified light curves and plot them with examples of the real and false classes.\n",
    "    \"\"\"\n",
    "    misclassifieds = []\n",
    "    for i,(f, lpredict, ltrue, lc, hr) in enumerate(zip(features, trained_labels, real_labels, lc_all, \\\n",
    "                                                hr_all)):\n",
    "        if lpredict == ltrue:\n",
    "            continue\n",
    "        else:\n",
    "            misclassifieds.append([f, lpredict, ltrue, lc, hr])\n",
    "\n",
    "    for j,m in enumerate(misclassifieds):\n",
    "        pos_human = np.random.choice([0,3], p=[0.5, 0.5])\n",
    "        pos_robot = int(3. - pos_human)\n",
    "\n",
    "        f = m[0]\n",
    "        lpredict = m[1]\n",
    "        ltrue = m[2]\n",
    "        times = m[3][0]\n",
    "        counts = m[3][1]\n",
    "        hr1 = m[4][0]\n",
    "        hr2 = m[4][1]\n",
    "        print(\"Predicted class is: \" + str(lpredict))\n",
    "        print(\"Human classified class is: \" + str(ltrue))\n",
    "        robot_all = [[lt, lp, lc, hr] for lt, lp, lc, hr in \\\n",
    "                     zip(real_labels, trained_labels, lc_all, hr_all)\\\n",
    "                     if lp == lpredict ]\n",
    "        human_all = [[lt, lp, lc, hr] for lt, lp, lc, hr in \\\n",
    "                     zip(real_labels, trained_labels, lc_all, hr_all)\\\n",
    "                     if lp == ltrue ]\n",
    "\n",
    "        np.random.shuffle(robot_all)\n",
    "        np.random.shuffle(human_all)\n",
    "        robot_all = robot_all[:6]\n",
    "        human_all = human_all[:6]\n",
    "\n",
    "        sns.set_style(\"darkgrid\")\n",
    "        current_palette = sns.color_palette()\n",
    "        fig = plt.figure(figsize=(10,15))\n",
    "\n",
    "        def plot_lcs(times, counts, hr1, hr2, xcoords, ycoords, colspan, rowspan):\n",
    "            #print(\"plotting in grid point \" + str((xcoords[0], ycoords[0])))\n",
    "            ax = plt.subplot2grid((9,6),(xcoords[0], ycoords[0]), colspan=colspan, rowspan=rowspan)\n",
    "            ax.plot(times, counts, lw=2, linestyle=\"steps-mid\", rasterized=True)\n",
    "            ax.set_xlim([times[0], times[-1]])\n",
    "            ax.set_ylim([0.0, 12000.0])\n",
    "            #print(\"plotting in grid point \" + str((xcoords[1], ycoords[1])))\n",
    "\n",
    "            #h, xedges, yedges = np.histogram2d(np.log(hr1), np.log(hr2), bins=40, \n",
    "            #                       range=hr_limits)\n",
    "            #h = np.rot90(h)\n",
    "            #h = np.flipud(h)\n",
    "\n",
    "            #hmax = np.max(h)\n",
    "            #print(hmax)\n",
    "            #hmask = np.where(h > hmax/20.)\n",
    "            #hmask1 = np.where(h < hmax/20.)\n",
    "\n",
    "            #hnew = copy.copy(h)\n",
    "            #hnew[hmask[0], hmask[1]] = 1.\n",
    "            #hnew[hmask1[0], hmask1[1]] = 0.0\n",
    "\n",
    "            #ax = plt.subplot2grid((9,6),(xcoords[1], ycoords[1]), colspan=colspan, rowspan=rowspan)\n",
    "            #ax.pcolormesh(xedges,yedges,hnew,cmap='BuPu')\n",
    "            #ax.scatter(hr1, hr2, facecolor=current_palette[1], edgecolor=\"none\", rasterized=True)\n",
    "            #ax.set_xlim(hr_limits[0])\n",
    "            #ax.set_ylim(hr_limits[1])\n",
    "\n",
    "            ax = plt.subplot2grid((9,6),(xcoords[1], ycoords[1]), colspan=colspan, rowspan=rowspan)\n",
    "            ax.scatter(hr1, hr2, facecolor=current_palette[1], edgecolor=\"none\", rasterized=True)\n",
    "            ax.set_xlim([.27, 0.85])\n",
    "            ax.set_ylim([0.04, 0.7])\n",
    "\n",
    "            #print(\"plotting in grid point \" + str((xcoords[2], ycoords[2])))    \n",
    "            ax = plt.subplot2grid((9,6),(xcoords[2], ycoords[2]), colspan=colspan, rowspan=rowspan)\n",
    "            dt = np.min(np.diff(times))\n",
    "            ps = powerspectrum.PowerSpectrum(times, counts=counts/dt, norm=\"rms\")\n",
    "            ps.freq = np.array(ps.freq)\n",
    "            ps.ps = np.array(ps.ps)*ps.freq\n",
    "            \n",
    "            binfreq = np.logspace(np.log10(ps.freq[1]), np.log10(ps.freq[-1]), 24)\n",
    "            binps, bin_edges, binno = scipy.stats.binned_statistic(ps.freq[1:], ps.ps[1:], statistic=\"mean\", bins=binfreq)\n",
    "\n",
    "            df = binfreq[1:]-binfreq[:-1]\n",
    "            binfreq = binfreq[:-1]+df/2.\n",
    "            ax.loglog(binfreq[1:], binps[1:], linestyle=\"steps-mid\", rasterized=True)\n",
    "            ax.set_xlim([ps.freq[1], ps.freq[-1]])\n",
    "            ax.set_ylim([1.e-6, 10.])\n",
    "\n",
    "            return\n",
    "\n",
    "        ## first plot misclassified:\n",
    "        plot_lcs(times, counts, hr1, hr2, [0,0,0], [0,2,4], 2, 2)\n",
    "\n",
    "        ## now plot examples\n",
    "        for i in range(4):\n",
    "            r = robot_all[i]\n",
    "            h = human_all[i]\n",
    "            #print(h[0])\n",
    "            #print(\"human indices: \" + str([ [i+3, i+3, i+3], [pos_human, pos_human+1, pos_human+2]]))\n",
    "            #print(\"robot indices: \" + str([[i+3, i+3, i+3], [pos_robot, pos_robot+1, pos_robot+2]]))\n",
    "            plot_lcs(h[2][0], h[2][1], h[3][0], h[3][1], [i+2, i+2, i+2], [pos_human, pos_human+1, pos_human+2], 1, 1)\n",
    "            plot_lcs(r[2][0], r[2][1], r[3][0], r[3][1], [i+2, i+2, i+2], [pos_robot, pos_robot+1, pos_robot+2], 1, 1)\n",
    "\n",
    "        ax = plt.subplot2grid((9,6),(8,pos_human+1))\n",
    "        ax.set_xlim([0,1])\n",
    "        ax.set_ylim([0,1])\n",
    "        ax.set_xlabel(\"Human: %s\"%ltrue, fontsize=20)\n",
    "        ax = plt.subplot2grid((9,6),(8,pos_robot+1))\n",
    "        ax.set_xlim([0,1])\n",
    "        ax.set_ylim([0,1])\n",
    "        ax.set_xlabel(\"Robot: %s\"%lpredict, fontsize=20)\n",
    "        #plt.show()\n",
    "        plt.savefig(datadir+\"misclassified%i.pdf\"%j, format=\"pdf\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hr2_min = -3.0\n",
    "hr2_max = 2.0\n",
    "hr1_min = -2.5\n",
    "hr1_max = 1.5\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.0, rc={\"axes.labelsize\": 14})\n",
    "plt.rc(\"font\", size=14, family=\"serif\", serif=\"Computer Sans\")\n",
    "plt.rc(\"axes\", titlesize=14, labelsize=14) \n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "\n",
    "plot_misclassifieds(features_new_val[:,:nfeatures], labels_rfc_red, labels_val, lc_val, hr_val, \n",
    "                    [[hr1_min, hr1_max],[hr2_min, hr2_max]],\n",
    "                    nexamples=6, namestr=\"misclassified\", datadir=\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying All Light Curves\n",
    "\n",
    "Based on the (imperfect) supervised learning, let's classify *all* light curves, even the ones where there is no human classification. \n",
    "\n",
    "Because we don't want to have to run the expensive greedy search every time, we'll use the feature ranking from the previous run, reshuffle and concatenate the feature vector such that it looks like the one we want to use for various purposes later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_ranking = [10, 16, 8, 1, 26, 24, 9, 7, 4, 22, 28, 11, 20, \n",
    "                   2, 15, 5, 12, 30, 18, 0, 27, 25, 6, 19, 3, 23, \n",
    "                   17, 13, 29, 21, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to need to use the data that has the *unclassified* data in it, at least for the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## we'll be using the first 20 re-ranked features\n",
    "max_features = 20\n",
    "\n",
    "## make new empty arrays for the ranked features\n",
    "features_new_train = np.zeros_like(features_train_full[:,:max_features])\n",
    "features_new_val = np.zeros_like(features_val_full[:,:max_features])\n",
    "features_new_test = np.zeros_like(features_test_full[:,:max_features])\n",
    "\n",
    "for i,f in enumerate(feature_ranking[:max_features]):\n",
    "    features_new_train[:,i] = features_train_full[:,f]\n",
    "    features_new_val[:,i] = features_val_full[:,f]\n",
    "    features_new_test[:,i] = features_test_full[:,f]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's scale all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_all = np.vstack((features_new_train, features_new_val, features_new_test))\n",
    "\n",
    "scaler_train = StandardScaler().fit(f_all)\n",
    "fscaled_train = scaler_train.transform(features_new_train)\n",
    "fscaled_val = scaler_train.transform(features_new_val)\n",
    "fscaled_test = scaler_train.transform(features_new_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll need to split out those features with human classifications versus those without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## human-classified features\n",
    "fscaled_train_human = fscaled_train[np.where(labels_train_full != \"None\")]\n",
    "fscaled_val_human = fscaled_val[np.where(labels_val_full != \"None\")]\n",
    "fscaled_test_human = fscaled_test[np.where(labels_test_full != \"None\")]\n",
    "\n",
    "## human classified labels\n",
    "labels_train= labels_train_full[np.where(labels_train_full != \"None\")]\n",
    "labels_test = labels_test_full[np.where(labels_test_full != \"None\")]\n",
    "labels_val = labels_val_full[np.where(labels_val_full != \"None\")]\n",
    "\n",
    "## unclassified features\n",
    "fscaled_train_unclass = fscaled_train[np.where(labels_train_full == \"None\")]\n",
    "fscaled_val_unclass = fscaled_val[np.where(labels_val_full == \"None\")]\n",
    "fscaled_test_unclass = fscaled_test[np.where(labels_test_full == \"None\")]\n",
    "\n",
    "## combine unclassified features\n",
    "fscaled_all_unclass = np.vstack((fscaled_train_unclass, fscaled_val_unclass, fscaled_test_unclass))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's do the supervised classification one last time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(fscaled_val.shape)\n",
    "### Random Forest Classifier\n",
    "params = {'max_depth': [3,5,7,10,15,20,30,50,75,100,150,200,250,300,400]}#,\n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(n_estimators=500), param_grid=params,\n",
    "                        verbose=0, n_jobs=4)\n",
    "grid_rfc.fit(fscaled_train_human, labels_train)\n",
    "\n",
    "print(\"Training accuracy: \" + str(grid_rfc.score(fscaled_train_human, labels_train)))\n",
    "print(\"Validation accuracy: \" + str(grid_rfc.score(fscaled_val_human, labels_val)))\n",
    "print(\"Test accuracy: \" + str(grid_rfc.score(fscaled_test_human, labels_test)))\n",
    "\n",
    "labels_rfc = grid_rfc.predict(fscaled_val_human)\n",
    "labels_rfc_test = grid_rfc.predict(fscaled_test_human)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_rfc_unclass = grid_rfc.predict(fscaled_all_unclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we've predicted labels for all unclassified segments, let's see what they look like.\n",
    "\n",
    "### Looking at a 2D representation of the features\n",
    "\n",
    "t-SNE provides a cool visualization of high-dimensional data spaces. We will take the 20 features and learn that representation for *all* segments at the same time. Do not do this at home unless you have a machine with lots of memory, or it'll crash!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsne = gt.getpickle(datadir+\"grs1915_%i_tsne.dat\"%seg_length_supervised)\n",
    "asdf = gt.getpickle(datadir+\"grs1915_%i_tsne_projected.dat\"%seg_length_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_all = np.hstack((labels_train, labels_val, labels_test, labels_rfc_unclass))\n",
    "\n",
    "label_set = np.unique(labels_all)\n",
    "labels_numeric = np.array([np.where(l == label_set)[0][0] for l in labels_all])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,9))\n",
    "gs = gridspec.GridSpec(1, 5)\n",
    "\n",
    "## background is white\n",
    "sns.set_style(\"white\")\n",
    "ax = plt.subplot(gs[:,:])\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "\n",
    "## this is the actual scatter plot\n",
    "sns.set_context(\"notebook\", font_scale=1.0, rc={\"axes.labelsize\": 16})\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rc(\"font\", size=16, family=\"serif\", serif=\"Computer Sans\")\n",
    "plt.rc(\"axes\", titlesize=16, labelsize=16) \n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "plt.subplots_adjust(top=0.95, bottom=0.08, left=0.08, right=0.97, hspace=0.2)\n",
    "\n",
    "ax1 = plt.subplot(gs[0,:4])\n",
    "\n",
    "## loop over all labels, make a scatter plot\n",
    "colors = [\"grey\"]\n",
    "colors.extend(np.loadtxt(\"colors.txt\"))\n",
    "for k, col in zip(range(nlabels), colors):\n",
    "    \n",
    "    my_members = labels_numeric == k\n",
    "    ax1.plot(asdf[my_members, 0], asdf[my_members, 1],\".\", color=col)\n",
    "\n",
    "    \n",
    "    \n",
    "### Now make a legend on the side of the plot\n",
    "lines = []\n",
    "# background of the legend is white\n",
    "sns.set_style(\"white\")\n",
    "ax2 = plt.subplot(gs[0,4])\n",
    "ax2.spines['top'].set_color('none')\n",
    "ax2.spines['bottom'].set_color('none')\n",
    "ax2.spines['left'].set_color('none')\n",
    "ax2.spines['right'].set_color('none')\n",
    "ax2.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "\n",
    "## for each label, make a non-existent line\n",
    "for i,l in enumerate(label_set):\n",
    "    line = mlines.Line2D([], [], color=colors[i], marker='o',\n",
    "                          markersize=9, label=l, linewidth=0, zorder=10)\n",
    "    lines.append(line)\n",
    "\n",
    "## now actually make the axis\n",
    "ax2.legend(handles=lines, loc='upper left', shadow=True)\n",
    "\n",
    "### labels for the entire plot\n",
    "ax.set_xlabel(\"Time in MJD\", fontsize=18)\n",
    "ax.set_ylabel(\"Count rate [counts/s]\", fontsize=18)\n",
    "\n",
    "plt.savefig(datadir+\"grs1915_%i_tsne.pdf\"%seg_length_unsupervised, format=\"pdf\")    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The overall distribution of states\n",
    "\n",
    "Let's plot the number of segments in which the source was in any given state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels_all = np.hstack((labels_train, labels_val, labels_test, labels_rfc_unclass))\n",
    "\n",
    "label_set = np.unique(labels_all)\n",
    "labels_numeric = np.array([np.where(l == label_set)[0][0] for l in labels_all])\n",
    "\n",
    "s = pd.Series(labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_all.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nstates = s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nstates.plot(kind='bar')\n",
    "plt.title(\"Distribution of classified states from the supervised classification\", fontsize=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylabel(\"Number of 1024-second segments in state\", fontsize=15)\n",
    "plt.savefig(datadir+\"grs1915_allclasses_supervised.pdf\", format=\"pdf\")\n",
    "#plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can translate that into seconds spent in a given state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nstates = s.value_counts()\n",
    "print(nstates.values)\n",
    "nstates *= 1024.0\n",
    "print(nstates.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nstates = s.value_counts()\n",
    "print(nstates.values)\n",
    "nstates *= 1024.0\n",
    "print(nstates.values)\n",
    "\n",
    "nstates.plot(kind='bar')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.title(\"Distribution of  states from the supervised classification\", fontsize=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylabel(\"Number of 1024-second segments in state\", fontsize=15)\n",
    "plt.savefig(datadir+\"grs1915_allclasses_supervised_seconds.pdf\", format=\"pdf\")\n",
    "#plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of states with time\n",
    "\n",
    "We'd like to know how these states are distributed over the duration of the observations, that is, all 16 years. For that, we'll need the time stamps of each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tstart_train_full = np.loadtxt(datadir+\"grs1915_%is_tstart_train.txt\"%seg_length_supervised)\n",
    "tstart_val_full = np.loadtxt(datadir+\"grs1915_%is_tstart_val.txt\"%seg_length_supervised)\n",
    "tstart_test_full = np.loadtxt(datadir+\"grs1915_%is_tstart_test.txt\"%seg_length_supervised)\n",
    "\n",
    "## human classified segments\n",
    "tstart_train = tstart_train_full[np.where(labels_train_full != \"None\")]\n",
    "tstart_test = tstart_test_full[np.where(labels_test_full != \"None\")]\n",
    "tstart_val = tstart_val_full[np.where(labels_val_full != \"None\")]\n",
    "\n",
    "## unclassified segments\n",
    "tstart_train_unclass = tstart_train_full[np.where(labels_train_full == \"None\")]\n",
    "tstart_val_unclass = tstart_val_full[np.where(labels_val_full == \"None\")]\n",
    "tstart_test_unclass = tstart_test_full[np.where(labels_test_full == \"None\")]\n",
    "\n",
    "\n",
    "tstart_all = np.hstack((tstart_train, tstart_val, tstart_test,\n",
    "                       tstart_train_unclass, tstart_val_unclass, tstart_test_unclass))\n",
    "\n",
    "\n",
    "mjdrefi = 49353. \n",
    "tstart_all /= (60*60*24.)\n",
    "tstart_all += mjdrefi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the ASM data so we can compare the states to the long-term light curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load and plot ASM light curve\n",
    "asm = np.loadtxt(datadir+\"grs1915_asm_lc.txt\",skiprows=5)\n",
    "\n",
    "asm_time = asm[:,0]\n",
    "asm_cr = asm[:,1]\n",
    "asm_total = asm_time[-1]-asm_time[0]\n",
    "print(\"The ASM light curve covers a total of %i days\"%asm_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make the plot. This code looks fairly complicated, but that's mostly fluff to make it look pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.lines as mlines\n",
    "## each light curve covers 500 days\n",
    "plot_len = 500.\n",
    "start_time = asm_time[0]\n",
    "end_time = start_time + plot_len\n",
    "\n",
    "fig = plt.figure(figsize=(12,15))\n",
    "gs = gridspec.GridSpec(11, 5)\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "ax = plt.subplot(gs[:,:])\n",
    "# Turn off axis lines and ticks of the big subplot\n",
    "\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.0, rc={\"axes.labelsize\": 16})\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "plt.rc(\"font\", size=16, family=\"serif\", serif=\"Computer Sans\")\n",
    "plt.rc(\"axes\", titlesize=16, labelsize=16) \n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "plt.subplots_adjust(top=0.95, bottom=0.08, left=0.08, right=0.97, hspace=0.2)\n",
    "\n",
    "current_palette = sns.color_palette(n_colors=len(label_set))\n",
    "colours = [current_palette[j] for j in labels_numeric]\n",
    "\n",
    "\n",
    "i = 0\n",
    "while end_time <= asm_time[-1]:\n",
    "    print(\"I am on plot %i.\"%i)\n",
    "    #ax1 = fig.add_subplot(11,1,i+1)\n",
    "    ax1 = plt.subplot(gs[i, :4])\n",
    "\n",
    "    ax1.errorbar(asm[:,0], asm[:,1], yerr = asm[:,2], linestyle=\"steps-mid\")\n",
    "    path = ax1.scatter(tstart_all, np.ones(len(tstart_all))*240., facecolor=colours,\n",
    "                edgecolor=\"None\")\n",
    "    ax1.set_xlim([start_time, end_time])\n",
    "    ax1.set_ylim([1.0, 299.0])\n",
    "    ax1.set_yticks(np.arange(3)*100.0+100.0, [100, 200, 300]);\n",
    "\n",
    "    start_time +=plot_len\n",
    "    end_time += plot_len\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "### HORRIBLY COMPLICATED WAY TO MAKE THE LEGEND    \n",
    "lines = []\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "ax2 = plt.subplot(gs[:3,4])\n",
    "\n",
    "# Turn off axis lines and ticks of the big subplot\n",
    "ax2.spines['top'].set_color('none')\n",
    "ax2.spines['bottom'].set_color('none')\n",
    "ax2.spines['left'].set_color('none')\n",
    "ax2.spines['right'].set_color('none')\n",
    "ax2.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "\n",
    "for i,l in enumerate(label_set):\n",
    "    line = mlines.Line2D([], [], color=current_palette[i], marker='o',\n",
    "                          markersize=9, label=l, linewidth=0, zorder=10)\n",
    "    lines.append(line)\n",
    "\n",
    "ax2.legend(handles=lines, loc='upper left', shadow=True)\n",
    "\n",
    "### LABELS\n",
    "ax.set_xlabel(\"Time in MJD\", fontsize=18)\n",
    "ax.set_ylabel(\"Count rate [counts/s]\", fontsize=18)\n",
    "\n",
    "plt.savefig(datadir+\"grs1915_asm_lc_all.pdf\", format=\"pdf\")\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Matrix between states\n",
    "\n",
    "We also want a matrix of the transition probabilities: given that the source is in state $k$, what is the probability it will transition to state $i$?\n",
    "\n",
    "First, we need to sort the labels by time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## stack labels and start times\n",
    "time_labels = np.vstack((tstart_all, labels_numeric)) \n",
    "\n",
    "## sorted lists\n",
    "tl_sorted = np.array(sorted(time_labels.T, key=lambda a_entry: a_entry[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## compute the difference between starting points of consecutive \n",
    "## segments in seconds\n",
    "dt = np.diff((tl_sorted[:,0]-mjdrefi)*(60*60.*24.))\n",
    "\n",
    "## find all indices where segments are more than 1024 seconds apart\n",
    "breakind = np.where(dt > seg_length_supervised)[0]\n",
    "\n",
    "sorted_times = tl_sorted[:,0]\n",
    "sorted_states = tl_sorted[:,1]\n",
    "\n",
    "sorted_states_new = [sorted_states[:breakind[0]]]\n",
    "for i in xrange(len(breakind[:-1])):\n",
    "    sorted_states_new.append(sorted_states[breakind[i]:breakind[i+1]])\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the transition matrix.\n",
    "\n",
    "**NOTE**: I should put in some handler for breaks between consecutive light curves that are longer than the duration of the light curve, because I don't know what the state was in between those!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "## number of unique states\n",
    "label_set = np.unique(sorted_states)\n",
    "nlabels = len(label_set)\n",
    "\n",
    "\n",
    "b_all = []\n",
    "for s in sorted_states_new:\n",
    "    b = np.zeros((nlabels,nlabels))\n",
    "\n",
    "    for (x,y), c in Counter(zip(s, s[1:])).iteritems():\n",
    "        b[x-1,y-1] = c\n",
    "\n",
    "    b_all.append(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_all = np.array(b_all)\n",
    "b = np.sum(b_all, axis=0)\n",
    "\n",
    "## normalize to make each row sum up to 1\n",
    "b = np.array([x/xsum for x,xsum in zip(b,np.sum(b, axis=1))])\n",
    "#b /= np.sum(b, axis=0)\n",
    "\n",
    "plt.matshow(b, cmap=cmap.Spectral_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Gaussian are my features?\n",
    "\n",
    "For a given class, I want to know how Gaussian my features are, because in the unsupervised part of the project, we're going to use a Gaussian Mixture Model (GMM) to specify the distribution of features into states. We're going to do that for the feature set that we have labels for only.\n",
    "\n",
    "So, for each state, we're now going to make histograms for each feature in order to gauge its Gaussianity. Double-peaked distributions are okay (these might separate out into separate states, or can be modeled by mixtures), but long-tailed distributions would be bad. \n",
    "\n",
    "\n",
    "Also, in the unsupervised learning, we'll be using the shorter segments, so let's look at those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datadir= \"../../\"\n",
    "seg_length_unsupervised = 256.\n",
    "\n",
    "features_train_full = np.loadtxt(datadir+\"grs1915_%is_features_train.txt\"%seg_length_unsupervised)\n",
    "features_test_full = np.loadtxt(datadir+\"grs1915_%is_features_test.txt\"%seg_length_unsupervised)\n",
    "features_val_full = np.loadtxt(datadir+\"grs1915_%is_features_val.txt\"%seg_length_unsupervised)\n",
    "\n",
    "labels_test_full = np.array(gt.conversion(datadir+\"grs1915_%is_labels_test.txt\"%seg_length_unsupervised)[0])\n",
    "labels_train_full = np.array(gt.conversion(datadir+\"grs1915_%is_labels_train.txt\"%seg_length_unsupervised)[0])\n",
    "labels_val_full = np.array(gt.conversion(datadir+\"grs1915_%is_labels_val.txt\"%seg_length_unsupervised)[0])\n",
    "\n",
    "tstart_train_full = np.loadtxt(datadir+\"grs1915_%is_tstart_train.txt\"%seg_length_unsupervised)\n",
    "tstart_test_full = np.loadtxt(datadir+\"grs1915_%is_tstart_test.txt\"%seg_length_unsupervised)\n",
    "tstart_val_full = np.loadtxt(datadir+\"grs1915_%is_tstart_val.txt\"%seg_length_unsupervised)\n",
    "\n",
    "feature_ranking = [10, 16, 8, 1, 26, 24, 9, 7, 4, 22, 28, 11, \n",
    "                   20, 2, 15, 5, 12, 30, 18, 0, 27, 25, 6, 19, \n",
    "                   3, 23, 17, 13, 29, 21, 14]\n",
    "\n",
    "## we'll be using the first 20 re-ranked features\n",
    "max_features = 20\n",
    "\n",
    "## make new empty arrays for the ranked features\n",
    "features_new_train = np.zeros_like(features_train_full[:,:max_features])\n",
    "features_new_val = np.zeros_like(features_val_full[:,:max_features])\n",
    "features_new_test = np.zeros_like(features_test_full[:,:max_features])\n",
    "\n",
    "for i,f in enumerate(feature_ranking[:max_features]):\n",
    "    if i in [0,2,3,6,7,11,13,15,16,19,20]:\n",
    "        print(\"Making a log of parameter %i\"%i)\n",
    "        features_new_train[:,i] = np.log(features_train_full[:,f])\n",
    "        features_new_val[:,i] = np.log(features_val_full[:,f])\n",
    "        features_new_test[:,i] = np.log(features_test_full[:,f])\n",
    "    else:\n",
    "        features_new_train[:,i] = features_train_full[:,f]\n",
    "        features_new_val[:,i] = features_val_full[:,f]\n",
    "        features_new_test[:,i] = features_test_full[:,f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_all = np.vstack((features_new_train, features_new_val, features_new_test))\n",
    "\n",
    "scaler_train = StandardScaler().fit(f_all)\n",
    "fscaled_train = scaler_train.transform(features_new_train)\n",
    "fscaled_val = scaler_train.transform(features_new_val)\n",
    "fscaled_test = scaler_train.transform(features_new_test)\n",
    "\n",
    "\n",
    "fscaled_train_human = fscaled_train[np.where(labels_train_full != \"None\")]\n",
    "fscaled_val_human= fscaled_val[np.where(labels_val_full != \"None\")]\n",
    "fscaled_test_human = fscaled_test[np.where(labels_test_full != \"None\")]\n",
    "\n",
    "fscaled_train_unclass = fscaled_train[np.where(labels_train_full == \"None\")]\n",
    "fscaled_val_unclass = fscaled_val[np.where(labels_val_full == \"None\")]\n",
    "fscaled_test_unclass = fscaled_test[np.where(labels_test_full == \"None\")]\n",
    "\n",
    "fscaled_all_human = np.vstack((fscaled_train_human, fscaled_val_human, fscaled_test_human))\n",
    "fscaled_all_unclass = np.vstack((fscaled_train_unclass, fscaled_val_unclass, fscaled_test_unclass))\n",
    "fscaled_all = np.vstack((fscaled_all_human, fscaled_all_unclass))\n",
    "\n",
    "labels_train= labels_train_full[np.where(labels_train_full != \"None\")]\n",
    "labels_val = labels_val_full[np.where(labels_val_full != \"None\")]\n",
    "labels_test = labels_test_full[np.where(labels_test_full != \"None\")]\n",
    "\n",
    "labels_train_unclass = labels_train_full[np.where(labels_train_full == \"None\")]\n",
    "labels_val_unclass = labels_val_full[np.where(labels_val_full == \"None\")]\n",
    "labels_test_unclass = labels_test_full[np.where(labels_test_full == \"None\")]\n",
    "\n",
    "labels_all_human = np.hstack((labels_train, labels_val, labels_test))\n",
    "labels_all_unclass = np.hstack((labels_train_unclass, labels_val_unclass, labels_test_unclass))\n",
    "labels_all = np.hstack((labels_all_human, labels_all_unclass))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make the set of labels\n",
    "label_set = np.unique(labels_all)\n",
    "\n",
    "## total number of labels\n",
    "nlabels = len(label_set)\n",
    "\n",
    "## make a numeric version of all labels\n",
    "labels_numeric = np.array([np.where(l == label_set)[0][0] for l in labels_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_names = [\"PC1\",\"HR1var\", \"PSDc\", \"median CR\", \"LF Weight\", \"LF Weight\", \"PSDd\", \"PSDb\", \"kurtosis CR\",\n",
    "                 \"LF Weight\", \"LF Weight\", \"PC2\", \"kurtosis HR2\", \"variance CR\", \"HR cov\", \"maxfreq\", \"mean HR1\",\n",
    "                 \"LF Weight\", \"HR2 skew\", \"mean CR\", \"LF Weight\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_features(fscaled_all, labels_all, feature_names, datadir=\"./\", froot=\"grs1915_features\"):\n",
    "    labels_unique = list(set(labels_all))\n",
    "\n",
    "    for lab in labels_unique:\n",
    "        fl = np.array([f for f,l in zip(fscaled_all, labels_all) if l == lab])\n",
    "\n",
    "        for j,features in  enumerate([feature_names[:10], feature_names[10:20]]):\n",
    "            \n",
    "            fig = plt.figure(figsize=(17,13))\n",
    "            nrows =3\n",
    "            ncolumns = 4\n",
    "\n",
    "            sns.set_style(\"white\")\n",
    "\n",
    "            ax = fig.add_subplot(111)\n",
    "            # Turn off axis lines and ticks of the big subplot\n",
    "\n",
    "            ax.spines['top'].set_color('none')\n",
    "            ax.spines['bottom'].set_color('none')\n",
    "            ax.spines['left'].set_color('none')\n",
    "            ax.spines['right'].set_color('none')\n",
    "            ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "\n",
    "            sns.set_context(\"notebook\", font_scale=1.5, rc={\"axes.labelsize\": 16, \"text.usetex\":True, \"font.family\":\"serif\"})\n",
    "            sns.set_style(\"darkgrid\")\n",
    "            plt.rc(\"text\", usetex=True)\n",
    "            plt.rc(\"axes\", titlesize=20, labelsize=20) \n",
    "            plt.rc(\"font\", size=24, family=\"serif\", serif=\"Computer Sans\")\n",
    "\n",
    "            for i,fn in enumerate(features):\n",
    "                if j == 0:\n",
    "                    f = fl[:,i]\n",
    "                if j == 1:\n",
    "                    f = fl[:,i+10]\n",
    "                #print(np.min(f))\n",
    "                #print(np.max(f))\n",
    "                ax1 = fig.add_subplot(nrows, ncolumns, i+1)\n",
    "                ax1.hist(f, bins=15, histtype=\"stepfilled\")\n",
    "                ax1.set_xlabel(fn)\n",
    "                #ax1.set_ylabel(\"p( \" + fn + \")\")\n",
    "                #ax1.get_xaxis().set_major_formatter(plt.LogFormatter(10,  labelOnlyBase=False))\n",
    "                #ax1.get_yaxis().set_major_formatter(plt.LogFormatter(10,  labelOnlyBase=False))\n",
    "\n",
    "            ax.set_title(\"Human class: \" + lab)\n",
    "            plt.savefig(datadir+froot+\"_%s%i.pdf\"%(lab,j), format=\"pdf\")\n",
    "            plt.close()\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now first run this on all the different classes for the supervised sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_features(fscaled_all_human, labels_all_human, feature_names, datadir=datadir, froot=\"grs1915_supervised_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the plots show quite Gaussian features, but many are double-peaked or very heavy-tailed. \n",
    "We'll take the logarithm of all parameters where this does not result in NaNs for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_params = [0,2,3,6,7,11,13,15,16,19,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
